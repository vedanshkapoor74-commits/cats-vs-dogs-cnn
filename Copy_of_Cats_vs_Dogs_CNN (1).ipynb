{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dx9llUqLcTHv"
      },
      "outputs": [],
      "source": [
        "# Core libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "\n",
        "# TensorFlow & Keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ”¹ Load Cats vs Dogs dataset\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "import math\n",
        "\n",
        "# Dataset constants\n",
        "IMG_SIZE = 150\n",
        "BATCH_SIZE = 32\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "# Load dataset (80% train, 20% validation)\n",
        "(train_ds, val_ds), ds_info = tfds.load(\n",
        "    'cats_vs_dogs',\n",
        "    split=['train[:80%]', 'train[80%:]'],\n",
        "    as_supervised=True,  # returns (image, label)\n",
        "    with_info=True\n",
        ")\n",
        "\n",
        "# ðŸ”¹ Preprocessing + Augmentation for training\n",
        "def preprocess_and_augment(image, label):\n",
        "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "    # Data augmentation\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
        "    image = tf.image.random_contrast(image, 0.8, 1.2)\n",
        "    image = image / 255.0\n",
        "    return image, label\n",
        "\n",
        "# ðŸ”¹ Preprocessing for validation (no augmentation)\n",
        "def preprocess_only(image, label):\n",
        "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "    image = image / 255.0\n",
        "    return image, label\n",
        "\n",
        "# ðŸ”¹ Prepare datasets for training\n",
        "train_ds = (train_ds\n",
        "            .map(preprocess_and_augment, num_parallel_calls=AUTOTUNE)\n",
        "            .shuffle(1000)\n",
        "            .batch(BATCH_SIZE)\n",
        "            .cache()\n",
        "            .prefetch(AUTOTUNE))\n",
        "\n",
        "val_ds = (val_ds\n",
        "          .map(preprocess_only, num_parallel_calls=AUTOTUNE)\n",
        "          .batch(BATCH_SIZE)\n",
        "          .cache()\n",
        "          .prefetch(AUTOTUNE))\n",
        "\n",
        "# ðŸ”¹ Print dataset info and batch counts\n",
        "num_train_batches = math.ceil(ds_info.splits['train'].num_examples * 0.8 / BATCH_SIZE)\n",
        "num_val_batches = math.ceil(ds_info.splits['train'].num_examples * 0.2 / BATCH_SIZE)\n",
        "\n",
        "print(ds_info)\n",
        "print(\"Training batches:\", num_train_batches)\n",
        "print(\"Validation batches:\", num_val_batches)"
      ],
      "metadata": {
        "id": "Ml2owLVMcdrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "(train_ds, val_ds), info = tfds.load(\n",
        "    \"cats_vs_dogs\",\n",
        "    split=['train[:80%]', 'train[80%:]'],\n",
        "    as_supervised=True,\n",
        "    with_info=True\n",
        ")\n",
        "\n",
        "# Number of classes\n",
        "num_classes = info.features[\"label\"].num_classes\n",
        "print(\"Number of classes:\", num_classes)\n",
        "\n",
        "# Dataset sizes\n",
        "print(\"Training examples:\", info.splits['train'].num_examples * 0.8)\n",
        "print(\"Validation examples:\", info.splits['train'].num_examples * 0.2)\n",
        "\n",
        "# Inspect few samples\n",
        "for image, label in train_ds.take(2):\n",
        "    print(\"Image shape:\", image.shape, \"Label:\", label.numpy())\n",
        "\n",
        "print(\"Class names:\", info.features[\"label\"].names)\n"
      ],
      "metadata": {
        "id": "hwCFDhHicl98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "IMG_SIZE = 150\n",
        "BATCH_SIZE = 32\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "# ðŸ”¹ Training preprocessing + augmentation\n",
        "def preprocess_and_augment(image, label):\n",
        "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
        "    image = tf.image.random_contrast(image, 0.8, 1.2)\n",
        "    return image, label\n",
        "\n",
        "# ðŸ”¹ Validation preprocessing (no augmentation)\n",
        "def preprocess_only(image, label):\n",
        "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    return image, label\n",
        "\n",
        "# ðŸ”¹ Apply preprocessing\n",
        "train_ds_aug = (\n",
        "    train_ds\n",
        "    .map(preprocess_and_augment, num_parallel_calls=AUTOTUNE)\n",
        "    .shuffle(1000)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(AUTOTUNE)\n",
        ")\n",
        "\n",
        "val_ds_preprocessed = (\n",
        "    val_ds\n",
        "    .map(preprocess_only, num_parallel_calls=AUTOTUNE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(AUTOTUNE)\n",
        ")"
      ],
      "metadata": {
        "id": "ZGAwtz7FdgT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
        "\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')  # Binary classification\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "x4HwOm3Ud36d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Callbacks\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.2,\n",
        "    patience=3,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=5,\n",
        "        restore_best_weights=True\n",
        "    ),\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        'best_model.keras',\n",
        "        monitor='val_loss',\n",
        "        save_best_only=True\n",
        "    ),\n",
        "    reduce_lr\n",
        "]"
      ],
      "metadata": {
        "id": "V1exu_kreE3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_ds_aug,\n",
        "    validation_data=val_ds_preprocessed,\n",
        "    epochs=20,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "id": "AV8A3owOeR4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training & validation accuracy and loss\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(len(acc))\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "# Accuracy Plot\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "# Loss Plot\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "gGOaAgkngpJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Get one batch from validation dataset\n",
        "for images, labels in val_ds_preprocessed.take(1):\n",
        "    break\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(images)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "for i in range(9):\n",
        "    plt.subplot(3, 3, i + 1)\n",
        "\n",
        "    img = images[i]\n",
        "    label = labels[i].numpy()\n",
        "\n",
        "    pred_prob = predictions[i][0]  # Probability of class 1 (Dog)\n",
        "    pred_label = 1 if pred_prob > 0.5 else 0\n",
        "\n",
        "    plt.imshow(img.numpy())\n",
        "    plt.axis('off')\n",
        "\n",
        "    true_class = \"Dog\" if label == 1 else \"Cat\"\n",
        "    predicted_class = \"Dog\" if pred_label == 1 else \"Cat\"\n",
        "\n",
        "    confidence = pred_prob if pred_label == 1 else 1 - pred_prob\n",
        "\n",
        "    plt.title(f\"True: {true_class}\\nPred: {predicted_class}\\nConf: {confidence:.2f}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Save final trained model\n",
        "model.save(\"cats_vs_dogs_cnn_model.keras\")"
      ],
      "metadata": {
        "id": "fCvoBSpWgvP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"cats_vs_dogs_cnn_model.keras\")"
      ],
      "metadata": {
        "id": "2HzzNo7d9a4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ”¹ Upload an image and predict Cat or Dog\n",
        "from google.colab import files\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load model if not in memory\n",
        "try:\n",
        "    model\n",
        "except NameError:\n",
        "    from tensorflow.keras.models import load_model\n",
        "    model = load_model(\"cats_vs_dogs_cnn_model.keras\")\n",
        "\n",
        "# Upload image\n",
        "uploaded = files.upload()\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "    img_path = filename\n",
        "    # Load and preprocess image\n",
        "    img = image.load_img(img_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
        "    img_array = image.img_to_array(img) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    # Make prediction\n",
        "    pred_prob = model.predict(img_array)[0][0]\n",
        "    pred_label = \"Dog\" if pred_prob > 0.5 else \"Cat\"\n",
        "    confidence = pred_prob if pred_label == \"Dog\" else 1 - pred_prob\n",
        "\n",
        "    # Display image and prediction\n",
        "    plt.figure(figsize=(4,4))\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"Prediction: {pred_label}\\nConfidence: {confidence:.2f}\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Uy6_CyMZABzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ”¹ Upload an image and predict Cat or Dog\n",
        "from google.colab import files\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load model if not in memory\n",
        "try:\n",
        "    model\n",
        "except NameError:\n",
        "    from tensorflow.keras.models import load_model\n",
        "    model = load_model(\"cats_vs_dogs_cnn_model.keras\")\n",
        "\n",
        "# Upload image\n",
        "uploaded = files.upload()\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "    img_path = filename\n",
        "    # Load and preprocess image\n",
        "    img = image.load_img(img_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
        "    img_array = image.img_to_array(img) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    # Make prediction\n",
        "    pred_prob = model.predict(img_array)[0][0]\n",
        "    pred_label = \"Dog\" if pred_prob > 0.5 else \"Cat\"\n",
        "    confidence = pred_prob if pred_label == \"Dog\" else 1 - pred_prob\n",
        "\n",
        "    # Display image and prediction\n",
        "    plt.figure(figsize=(4,4))\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"Prediction: {pred_label}\\nConfidence: {confidence:.2f}\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "W_15EkjfAaSm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}